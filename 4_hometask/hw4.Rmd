---
title: "Untitled"
author: "Lavrentiy"
date: '22 мая 2017 г '
output: html_document
---

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(randomForest)
library(dplyr)
library(ggplot2)

set.seed(42)
```



###Данные 
Данные - из статьи “A novel strategy for forensic age prediction by DNA methylation and support vector regression model”, Cheng Xu et al, Scientific reports 2015. Авторы попытались построить предсказатель возраста человека по данным метилирования отдельных CpG sites.

ages.tsv -- идентификаторы доноров: возраст, и название array, которым это всё добро сделали.

methylation.tsv -- данные про CpG сайты: где эти сайты на геноме находятся, доля метилирования каждого сайта у наших доноров. Однако в этой табличке также есть NA-значения, авторы статьи утверждают, что это означает “no methylation detected”, и считают их за 0

```{r echo=FALSE, warning=FALSE, cashe = T}
ages <- read.table("ages.tsv", sep="\t", header=1)
methylation <- read.table("methylation.tsv", sep="\t", header=1, row.names = 1, na.strings = "NA")
methylation[is.na(methylation)] <- 0
```


###Предподготовка данных 
Тут магия, на самом деле получается, что авторы статья сделали ручками feature selection, ну мы посмотрим только на те сайты метилирования, которые лучше всего скорелированны с возрастом. Нам вообще нужно сделать нормальную тестовую и валидирующую выборку — этим мы и займемся. Взяв 10 cайтов и откортировав их по модулю.



```{r echo=FALSE, warning=FALSE, cashe = T}
methylation_s <- t(methylation[, 4:ncol(methylation)]) #meth_t
correlation_age_methylation <- apply(methylation_s, 2, function(x) cor(as.numeric(x), ages$Age))
top_ten <- correlation_age_methylation[order(abs(correlation_age_methylation), decreasing = TRUE)][1:10]
methylation_s <- methylation_s[,names(top_ten)]

final <- as.data.frame(cbind(age=ages$Age, methylation_s))
rownames(final) <- ages$Sample


training <- sample(1:50, 40)
validation <- (1:50)[-training]

train <- final[training, -1]
valid <- final[validation, -1]

train.response <- final[training, 1]
valid.response <- final[validation, 1]
```


###Рабочая функция
Для анализа нам нужна будет функция-обертка, которая все сделает за нас: она принимает на вход data и response, в цикле по runs.number проводит кросс-валидацию для разных разбиений на тренировочную и тестовую выборки в соотношении 80/20, возвращает среднее по всем прогонам для тренировочной и тестовой выборок.


```{r echo=FALSE, warning=FALSE, cashe = T}

wrapper <- function(train.data, train.response,
                    test.data, test.response, 
                    runs.number=50, ...) {
  train_all <- vector(length = runs.number)
  test_all <- vector(length = runs.number)

  for (i in (1:runs.number)){
  fit.rf <- randomForest(train.response ~ .,
                       data=train.data, ...) 
  prediction_train <- predict(fit.rf, train.data)
  train_all[i] <- sqrt(sum((prediction_train - train.response)^2)/40)
  prediction_valid <- predict(fit.rf, test.data) 
  test_all[i] <- sqrt(sum((prediction_valid - test.response)^2)/10)
  }
return(c(mean(train_all),mean(test_all)))
}

```
###Оптимизация обучения

Параметры случайного леса Мы будем оптимизировать наш случайный лес по нескольким параметрам (эти параметры, являются аргументами функции randomForest). Напомню для сводки, что пускай NN – количество объектов в тренировочном датасете, MM – количество features в нашем датасете.

    ntree – количество деревьев в случайном лесе, по умолчанию 500

    replace – когда делается bagging (bootstrapping) нашего случайного леса, должны мы это делать с возвращением, или нет? По умолчанию, мы делает bagging с возвращением.

    sampsize – когда делается bagging (bootstrapping) нашего случайного леса, сколько мы должны взять объектов из тренировочного датасета? По умолчанию, если replace==TRUE мы берем все NN объектов, а если FALSE, то 23N

    nodesize – минимальный размер (по количеству объектов) для листовых вершин, значение по умолчанию – 5

    mtry – количество признаков, которое случайно выбирается при каждом разбиении (это также называется feature bagging)

Таким образом, если бы мы хотели, чтобы в нашем лесу, все деревья были переобучены, мы бы запустили это как-нибудь в духе:


###Займемся оптимизацией количества деревьев

```{r echo=FALSE, warning=FALSE, cashe = TRUE}
tree_num <- seq(1, 1000, 5)
ntrees <- sapply(tree_num, function(x) wrapper(train, train.response, valid, valid.response, runs.number = 100, ntree=x))

plot1 <- rbind(
    data.frame(trees=tree_num, SSE=ntrees[1,], dataset="Train"),
    data.frame(trees=tree_num, SSE=ntrees[2,], dataset="Validation")
  )
  
ggplot(data=plot1, aes(x=trees, y=SSE, color=dataset)) +
    geom_point(size=2) + 
    geom_line(size=1) + ggtitle("Optimize ntree") +
    theme_bw() + scale_y_continuous(breaks=seq(0, 20, 2))

NTREE <-100 

```
Ну тут немного без разницы сколько выбирать, после 250 вообще можно забить на количество, берем поменьше (100), ибо очень долго ждать




###Посмотрим, какие параметры для replace и sampsize делают наше обучение лучше:

#replace

```{r  echo=FALSE, warning=FALSE, cashe = TRUE}
ssize <- data.frame(matrix(unlist((lapply(1:40, function(x) c(x, wrapper(train, train.response, valid, valid.response, ntree=100, mtry=10, nodesize=1, sampsize=x, replace=F))))),ncol = 3, byrow=T))
tr <- ssize[, 1:2]
colnames(tr) <- c("Sampsize", "RMSE")
val <- ssize[, c(1,3)]
colnames(val) <- c("Sampsize", "RMSE")
tr$dataset <- "Train"
val$dataset <- "Validation"
ssize <- rbind(tr, val)
ggplot(ssize, aes(Sampsize, RMSE, col=dataset))+
    geom_point(size=3) + 
    geom_line(size=2) + ggtitle("SSE Plot Replace False") +
    theme_bw()

```

#sampsize

```{r echo=FALSE, warning=FALSE, cashe = TRUE}
ssize <- data.frame(matrix(unlist((lapply(1:40, function(x) c(x, wrapper(train, train.response, valid, valid.response, ntree=100, mtry=10, nodesize=1, sampsize=x, replace=T))))),ncol = 3, byrow=T))
tr <- ssize[, 1:2]
colnames(tr) <- c("Sampsize", "RMSE")
val <- ssize[, c(1,3)]
colnames(val) <- c("Sampsize", "RMSE")
tr$dataset <- "Train"
val$dataset <- "Validation"
ssize <- rbind(tr, val)
ggplot(ssize, aes(Sampsize, RMSE, col=dataset))+
    geom_point(size=3) + 
    geom_line(size=2) + ggtitle("SSE Plot Replace True") +
    theme_bw()


REPLACE <- TRUE
NSAMP <- 40
```


Сильнее переобучается модель, в которой установлен параметр replace=F. Поэтому установим replace = T и NSAMP = 40

###Оптимизируем возможное количество образцов в листьях.

```{r echo=FALSE, warning=FALSE, cashe = TRUE}
nnode <-  seq(1, 40, 1)
nnodes <- sapply(nnode, function(x) wrapper(train, train.response, valid, valid.response, runs.number = 100, replace=REPLACE, sampsize=NSAMP, ntree=NTREE, nodesize=x, mtry=10))

plot_node <- rbind(
    data.frame(nodes=nnode, SSE=nnodes[1,], dataset="Train"),
    data.frame(nodes=nnode, SSE=nnodes[2,], dataset="Validation")
     )

ggplot(data=plot_node, aes(x=nodes, y=SSE, color=dataset)) +
    geom_point(size=3) +
    geom_line(size=2) + ggtitle("SSE Plot Nodes") +
    theme_bw()
NNODE <- 1
```

Переобучения здесь вроде нет. Установим nodesize = r NNODE.


###MTRY

```{r echo=FALSE, warning=FALSE, cashe = TRUE}
nmtry <- seq(1, 10, 1)
nmtries <- sapply(nmtry, function(x) wrapper(train, train.response, valid, valid.response, runs.number = 100, replace=REPLACE, sampsize=NSAMP, ntree=NTREE, nodesize=NNODE, mtry=x))

toPlot_mtry <- rbind(
    data.frame(mtry=nmtry, SSE=nmtries[1,], dataset="Train"),
    data.frame(mtry=nmtry, SSE=nmtries[2,], dataset="Validation")
     )

ggplot(data=toPlot_mtry, aes(x=mtry, y=SSE, color=dataset)) +
    geom_point(size=3) + 
    geom_line(size=2) + ggtitle("SSE Plot Mtry") +
    theme_bw()
NMTRY <- 2
```
Переобучение здесь бросается в глаза с значения mtry=2. Установим mtry=r NMTRY


###CROSS VALIDATION

Проведем кросс-валидацию с установленными параметрами и сравним с результатами, полученными с параметрами по умолчанию.

#Параметры по умолчанию

```{r echo=FALSE, warning=FALSE, cashe = TRUE}
cross.validation <- matrix(sample(1:50, 50), nrow=5, ncol=10)
cross.results <- apply(cross.validation, 1, function(validation){
  train.sample <- (1:50)[-validation]
  train.data <- final[train.sample, -1]
  train.response <- final$age[train.sample]
  test.data <- final[validation, -1]
  test.response <- final$age[validation]
  return(wrapper(train.data, train.response, test.data, test.response, 100))
})

```

#Оптимизированные параметры

```{r echo=FALSE, warning=FALSE, cashe = TRUE}
cross.results.optimise <- apply(cross.validation, 1, function(validation){
  train.sample <- (1:50)[-validation]
  train.data <- final[train.sample, -1]
  train.response <- final$age[train.sample]
  test.data <- final[validation, -1]
  test.response <- final$age[validation]
  return(wrapper(train.data, train.response, test.data, test.response, 100, ntree = NTREE, mtry=NMTRY, nodesize=NNODE, replace=REPLACE, sampsize = NSAMP))
})
```


#Сравнение с данными по умолчанию
```{r echo=FALSE, warning=FALSE, cashe = TRUE}

print(rowMeans(cross.results) - rowMeans(cross.results.optimise))
```

Ну немного потанцевав мы получили небольшое улучшение результата.. но можно добиться большего сыграв трюк и попытаться формировать искусственную и  выборку на основании данных.. но вот что отбирать стало непонятно на стадии отбора сайтов.
